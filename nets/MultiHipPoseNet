digraph {
	graph [size="270.3,270.3"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	139218443670928 [label="
 (1, 8, 384, 512)" fillcolor=darkolivegreen1]
	139218615516848 [label=ConvolutionBackward0]
	139218615516944 -> 139218615516848
	139218615516944 [label=ReluBackward0]
	139218615516992 -> 139218615516944
	139218615516992 [label=NativeGroupNormBackward0]
	139218615517088 -> 139218615516992
	139218615517088 [label=ReluBackward0]
	139218443706528 -> 139218615517088
	139218443706528 [label=ConvolutionBackward0]
	139218443706624 -> 139218443706528
	139218443706624 [label=ReluBackward0]
	139218443706816 -> 139218443706624
	139218443706816 [label=ConvolutionBackward0]
	139218443706912 -> 139218443706816
	139218443706912 [label=UpsampleBilinear2DBackward0]
	139218443707104 -> 139218443706912
	139218443707104 [label=ReluBackward0]
	139218443707200 -> 139218443707104
	139218443707200 [label=ConvolutionBackward0]
	139218443707296 -> 139218443707200
	139218443707296 [label=ReluBackward0]
	139218443707440 -> 139218443707296
	139218443707440 [label=ConvolutionBackward0]
	139218443707536 -> 139218443707440
	139218443707536 [label=CatBackward0]
	139218443707680 -> 139218443707536
	139218443707680 [label=ReluBackward0]
	139218443707824 -> 139218443707680
	139218443707824 [label=NativeGroupNormBackward0]
	139218443707920 -> 139218443707824
	139218443707920 [label=ConvolutionBackward0]
	139218443708112 -> 139218443707920
	139218443708112 [label=MulBackward0]
	139218443708304 -> 139218443708112
	139218443708304 [label=CatBackward0]
	139218443708448 -> 139218443708304
	139218443708448 [label=ReluBackward0]
	139218443708544 -> 139218443708448
	139218443708544 [label=NativeGroupNormBackward0]
	139218443708640 -> 139218443708544
	139218443708640 [label=ConvolutionBackward0]
	139218443708832 -> 139218443708640
	139218712810896 [label="Expert_Gate.expert_layers.0.conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	139218712810896 -> 139218443708832
	139218443708832 [label=AccumulateGrad]
	139218443708592 -> 139218443708544
	139218712810816 [label="Expert_Gate.expert_layers.0.bn1.weight
 (64)" fillcolor=lightblue]
	139218712810816 -> 139218443708592
	139218443708592 [label=AccumulateGrad]
	139218443708352 -> 139218443708544
	139218712810976 [label="Expert_Gate.expert_layers.0.bn1.bias
 (64)" fillcolor=lightblue]
	139218712810976 -> 139218443708352
	139218443708352 [label=AccumulateGrad]
	139218443708256 -> 139218443708112
	139218443708256 [label=AddBackward0]
	139218443708688 -> 139218443708256
	139218443708688 [label=TanhBackward0]
	139218443708928 -> 139218443708688
	139218443708928 [label=AddBackward0]
	139218443708736 -> 139218443708928
	139218443708736 [label=MulBackward0]
	139218443709072 -> 139218443708736
	139218443709072 [label=MulBackward0]
	139218443709216 -> 139218443709072
	139218443709216 [label=PowBackward0]
	139218443709360 -> 139218443709216
	139218443709360 [label=AddBackward0]
	139218443709456 -> 139218443709360
	139218443709456 [label=SumBackward1]
	139218443709552 -> 139218443709456
	139218443709552 [label=PowBackward0]
	139218443708304 -> 139218443709552
	139218443709168 -> 139218443709072
	139218615506960 [label="Expert_Gate.fusion_modules.0.alpha
 (1, 64, 1, 1)" fillcolor=lightblue]
	139218615506960 -> 139218443709168
	139218443709168 [label=AccumulateGrad]
	139218443709024 -> 139218443708736
	139218443709024 [label=DivBackward0]
	139218443709408 -> 139218443709024
	139218615507040 [label="Expert_Gate.fusion_modules.0.gamma
 (1, 64, 1, 1)" fillcolor=lightblue]
	139218615507040 -> 139218443709408
	139218443709408 [label=AccumulateGrad]
	139218443709504 -> 139218443709024
	139218443709504 [label=PowBackward0]
	139218443709312 -> 139218443709504
	139218443709312 [label=AddBackward0]
	139218443709696 -> 139218443709312
	139218443709696 [label=MeanBackward1]
	139218443709792 -> 139218443709696
	139218443709792 [label=PowBackward0]
	139218443709072 -> 139218443709792
	139218443708880 -> 139218443708928
	139218615507120 [label="Expert_Gate.fusion_modules.0.beta
 (1, 64, 1, 1)" fillcolor=lightblue]
	139218615507120 -> 139218443708880
	139218443708880 [label=AccumulateGrad]
	139218443708064 -> 139218443707920
	139218615507520 [label="Expert_Gate.fusion_modules.0.conv.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	139218615507520 -> 139218443708064
	139218443708064 [label=AccumulateGrad]
	139218443708016 -> 139218443707920
	139218615507600 [label="Expert_Gate.fusion_modules.0.conv.bias
 (64)" fillcolor=lightblue]
	139218615507600 -> 139218443708016
	139218443708016 [label=AccumulateGrad]
	139218443707872 -> 139218443707824
	139218615507680 [label="Expert_Gate.fusion_modules.0.bn.weight
 (64)" fillcolor=lightblue]
	139218615507680 -> 139218443707872
	139218443707872 [label=AccumulateGrad]
	139218443707728 -> 139218443707824
	139218615507760 [label="Expert_Gate.fusion_modules.0.bn.bias
 (64)" fillcolor=lightblue]
	139218615507760 -> 139218443707728
	139218443707728 [label=AccumulateGrad]
	139218443707632 -> 139218443707536
	139218443707632 [label=UpsampleBilinear2DBackward0]
	139218443708160 -> 139218443707632
	139218443708160 [label=ReluBackward0]
	139218443708496 -> 139218443708160
	139218443708496 [label=ConvolutionBackward0]
	139218443708400 -> 139218443708496
	139218443708400 [label=ReluBackward0]
	139218443708976 -> 139218443708400
	139218443708976 [label=ConvolutionBackward0]
	139218443709744 -> 139218443708976
	139218443709744 [label=CatBackward0]
	139218443709600 -> 139218443709744
	139218443709600 [label=ReluBackward0]
	139218443710032 -> 139218443709600
	139218443710032 [label=NativeGroupNormBackward0]
	139218443710128 -> 139218443710032
	139218443710128 [label=ConvolutionBackward0]
	139218443710320 -> 139218443710128
	139218443710320 [label=MulBackward0]
	139218443710416 -> 139218443710320
	139218443710416 [label=CatBackward0]
	139218443731200 -> 139218443710416
	139218443731200 [label=ReluBackward0]
	139218443731296 -> 139218443731200
	139218443731296 [label=AddBackward0]
	139218443731392 -> 139218443731296
	139218443731392 [label=NativeGroupNormBackward0]
	139218443731536 -> 139218443731392
	139218443731536 [label=ConvolutionBackward0]
	139218443731728 -> 139218443731536
	139218443731728 [label=ReluBackward0]
	139218443731872 -> 139218443731728
	139218443731872 [label=NativeGroupNormBackward0]
	139218443731968 -> 139218443731872
	139218443731968 [label=ConvolutionBackward0]
	139218443732160 -> 139218443731968
	139218443732160 [label=ReluBackward0]
	139218443732304 -> 139218443732160
	139218443732304 [label=NativeGroupNormBackward0]
	139218443732400 -> 139218443732304
	139218443732400 [label=ConvolutionBackward0]
	139218443731344 -> 139218443732400
	139218443731344 [label=ReluBackward0]
	139218443732688 -> 139218443731344
	139218443732688 [label=AddBackward0]
	139218443732784 -> 139218443732688
	139218443732784 [label=NativeGroupNormBackward0]
	139218443732928 -> 139218443732784
	139218443732928 [label=ConvolutionBackward0]
	139218443733120 -> 139218443732928
	139218443733120 [label=ReluBackward0]
	139218443733264 -> 139218443733120
	139218443733264 [label=NativeGroupNormBackward0]
	139218443733360 -> 139218443733264
	139218443733360 [label=ConvolutionBackward0]
	139218443733552 -> 139218443733360
	139218443733552 [label=ReluBackward0]
	139218443733696 -> 139218443733552
	139218443733696 [label=NativeGroupNormBackward0]
	139218443733792 -> 139218443733696
	139218443733792 [label=ConvolutionBackward0]
	139218443732736 -> 139218443733792
	139218443732736 [label=ReluBackward0]
	139218443734080 -> 139218443732736
	139218443734080 [label=AddBackward0]
	139218443734176 -> 139218443734080
	139218443734176 [label=NativeGroupNormBackward0]
	139218443734320 -> 139218443734176
	139218443734320 [label=ConvolutionBackward0]
	139218443734512 -> 139218443734320
	139218443734512 [label=ReluBackward0]
	139218443734656 -> 139218443734512
	139218443734656 [label=NativeGroupNormBackward0]
	139218443734752 -> 139218443734656
	139218443734752 [label=ConvolutionBackward0]
	139218443734944 -> 139218443734752
	139218443734944 [label=ReluBackward0]
	139218443734992 -> 139218443734944
	139218443734992 [label=NativeGroupNormBackward0]
	139218443743392 -> 139218443734992
	139218443743392 [label=ConvolutionBackward0]
	139218443743680 -> 139218443743392
	139218443743680 [label=MaxPool2DWithIndicesBackward0]
	139218443708448 -> 139218443743680
	139218443743632 -> 139218443743392
	139218712811296 [label="Expert_Gate.expert_layers.0.layer1.0.conv1.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	139218712811296 -> 139218443743632
	139218443743632 [label=AccumulateGrad]
	139218443743296 -> 139218443734992
	139218712811376 [label="Expert_Gate.expert_layers.0.layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	139218712811376 -> 139218443743296
	139218443743296 [label=AccumulateGrad]
	139218443743488 -> 139218443734992
	139218712811456 [label="Expert_Gate.expert_layers.0.layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	139218712811456 -> 139218443743488
	139218443743488 [label=AccumulateGrad]
	139218443734896 -> 139218443734752
	139218712811696 [label="Expert_Gate.expert_layers.0.layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139218712811696 -> 139218443734896
	139218443734896 [label=AccumulateGrad]
	139218443734704 -> 139218443734656
	139218712811616 [label="Expert_Gate.expert_layers.0.layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	139218712811616 -> 139218443734704
	139218443734704 [label=AccumulateGrad]
	139218443734560 -> 139218443734656
	139218712811776 [label="Expert_Gate.expert_layers.0.layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	139218712811776 -> 139218443734560
	139218443734560 [label=AccumulateGrad]
	139218443734464 -> 139218443734320
	139218712811936 [label="Expert_Gate.expert_layers.0.layer1.0.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	139218712811936 -> 139218443734464
	139218443734464 [label=AccumulateGrad]
	139218443734272 -> 139218443734176
	139218712812016 [label="Expert_Gate.expert_layers.0.layer1.0.bn3.weight
 (256)" fillcolor=lightblue]
	139218712812016 -> 139218443734272
	139218443734272 [label=AccumulateGrad]
	139218443734224 -> 139218443734176
	139218712812096 [label="Expert_Gate.expert_layers.0.layer1.0.bn3.bias
 (256)" fillcolor=lightblue]
	139218712812096 -> 139218443734224
	139218443734224 [label=AccumulateGrad]
	139218443734128 -> 139218443734080
	139218443734128 [label=NativeGroupNormBackward0]
	139218443734848 -> 139218443734128
	139218443734848 [label=ConvolutionBackward0]
	139218443743680 -> 139218443734848
	139218443734608 -> 139218443734848
	139218712811056 [label="Expert_Gate.expert_layers.0.layer1.0.downsample.0.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	139218712811056 -> 139218443734608
	139218443734608 [label=AccumulateGrad]
	139218443734416 -> 139218443734128
	139218712811136 [label="Expert_Gate.expert_layers.0.layer1.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	139218712811136 -> 139218443734416
	139218443734416 [label=AccumulateGrad]
	139218443734368 -> 139218443734128
	139218712811216 [label="Expert_Gate.expert_layers.0.layer1.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	139218712811216 -> 139218443734368
	139218443734368 [label=AccumulateGrad]
	139218443733984 -> 139218443733792
	139218712812256 [label="Expert_Gate.expert_layers.0.layer1.1.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	139218712812256 -> 139218443733984
	139218443733984 [label=AccumulateGrad]
	139218443733744 -> 139218443733696
	139218712812336 [label="Expert_Gate.expert_layers.0.layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	139218712812336 -> 139218443733744
	139218443733744 [label=AccumulateGrad]
	139218443733600 -> 139218443733696
	139218712812416 [label="Expert_Gate.expert_layers.0.layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	139218712812416 -> 139218443733600
	139218443733600 [label=AccumulateGrad]
	139218443733504 -> 139218443733360
	139218712812656 [label="Expert_Gate.expert_layers.0.layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139218712812656 -> 139218443733504
	139218443733504 [label=AccumulateGrad]
	139218443733312 -> 139218443733264
	139218712812576 [label="Expert_Gate.expert_layers.0.layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	139218712812576 -> 139218443733312
	139218443733312 [label=AccumulateGrad]
	139218443733168 -> 139218443733264
	139218712812736 [label="Expert_Gate.expert_layers.0.layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	139218712812736 -> 139218443733168
	139218443733168 [label=AccumulateGrad]
	139218443733072 -> 139218443732928
	139218712812896 [label="Expert_Gate.expert_layers.0.layer1.1.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	139218712812896 -> 139218443733072
	139218443733072 [label=AccumulateGrad]
	139218443732880 -> 139218443732784
	139218712812976 [label="Expert_Gate.expert_layers.0.layer1.1.bn3.weight
 (256)" fillcolor=lightblue]
	139218712812976 -> 139218443732880
	139218443732880 [label=AccumulateGrad]
	139218443732832 -> 139218443732784
	139218712813056 [label="Expert_Gate.expert_layers.0.layer1.1.bn3.bias
 (256)" fillcolor=lightblue]
	139218712813056 -> 139218443732832
	139218443732832 [label=AccumulateGrad]
	139218443732736 -> 139218443732688
	139218443732592 -> 139218443732400
	139218712813216 [label="Expert_Gate.expert_layers.0.layer1.2.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	139218712813216 -> 139218443732592
	139218443732592 [label=AccumulateGrad]
	139218443732352 -> 139218443732304
	139218712813296 [label="Expert_Gate.expert_layers.0.layer1.2.bn1.weight
 (64)" fillcolor=lightblue]
	139218712813296 -> 139218443732352
	139218443732352 [label=AccumulateGrad]
	139218443732208 -> 139218443732304
	139218712813376 [label="Expert_Gate.expert_layers.0.layer1.2.bn1.bias
 (64)" fillcolor=lightblue]
	139218712813376 -> 139218443732208
	139218443732208 [label=AccumulateGrad]
	139218443732112 -> 139218443731968
	139218632286352 [label="Expert_Gate.expert_layers.0.layer1.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139218632286352 -> 139218443732112
	139218443732112 [label=AccumulateGrad]
	139218443731920 -> 139218443731872
	139218632286272 [label="Expert_Gate.expert_layers.0.layer1.2.bn2.weight
 (64)" fillcolor=lightblue]
	139218632286272 -> 139218443731920
	139218443731920 [label=AccumulateGrad]
	139218443731776 -> 139218443731872
	139218632286432 [label="Expert_Gate.expert_layers.0.layer1.2.bn2.bias
 (64)" fillcolor=lightblue]
	139218632286432 -> 139218443731776
	139218443731776 [label=AccumulateGrad]
	139218443731680 -> 139218443731536
	139218632286592 [label="Expert_Gate.expert_layers.0.layer1.2.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	139218632286592 -> 139218443731680
	139218443731680 [label=AccumulateGrad]
	139218443731488 -> 139218443731392
	139218632286672 [label="Expert_Gate.expert_layers.0.layer1.2.bn3.weight
 (256)" fillcolor=lightblue]
	139218632286672 -> 139218443731488
	139218443731488 [label=AccumulateGrad]
	139218443731440 -> 139218443731392
	139218632286752 [label="Expert_Gate.expert_layers.0.layer1.2.bn3.bias
 (256)" fillcolor=lightblue]
	139218632286752 -> 139218443731440
	139218443731440 [label=AccumulateGrad]
	139218443731344 -> 139218443731296
	139218443731056 -> 139218443710320
	139218443731056 [label=AddBackward0]
	139218443731104 -> 139218443731056
	139218443731104 [label=TanhBackward0]
	139218443731632 -> 139218443731104
	139218443731632 [label=AddBackward0]
	139218443732016 -> 139218443731632
	139218443732016 [label=MulBackward0]
	139218443732448 -> 139218443732016
	139218443732448 [label=MulBackward0]
	139218443732496 -> 139218443732448
	139218443732496 [label=PowBackward0]
	139218443733456 -> 139218443732496
	139218443733456 [label=AddBackward0]
	139218443733216 -> 139218443733456
	139218443733216 [label=SumBackward1]
	139218443733840 -> 139218443733216
	139218443733840 [label=PowBackward0]
	139218443710416 -> 139218443733840
	139218443732976 -> 139218443732448
	139218615507840 [label="Expert_Gate.fusion_modules.1.alpha
 (1, 256, 1, 1)" fillcolor=lightblue]
	139218615507840 -> 139218443732976
	139218443732976 [label=AccumulateGrad]
	139218443732544 -> 139218443732016
	139218443732544 [label=DivBackward0]
	139218443733408 -> 139218443732544
	139218615507920 [label="Expert_Gate.fusion_modules.1.gamma
 (1, 256, 1, 1)" fillcolor=lightblue]
	139218615507920 -> 139218443733408
	139218443733408 [label=AccumulateGrad]
	139218443733936 -> 139218443732544
	139218443733936 [label=PowBackward0]
	139218443733024 -> 139218443733936
	139218443733024 [label=AddBackward0]
	139218443733888 -> 139218443733024
	139218443733888 [label=MeanBackward1]
	139218443734032 -> 139218443733888
	139218443734032 [label=PowBackward0]
	139218443732448 -> 139218443734032
	139218443732064 -> 139218443731632
	139218615508000 [label="Expert_Gate.fusion_modules.1.beta
 (1, 256, 1, 1)" fillcolor=lightblue]
	139218615508000 -> 139218443732064
	139218443732064 [label=AccumulateGrad]
	139218443710272 -> 139218443710128
	139218615508320 [label="Expert_Gate.fusion_modules.1.conv.weight
 (256, 256, 1, 1)" fillcolor=lightblue]
	139218615508320 -> 139218443710272
	139218443710272 [label=AccumulateGrad]
	139218443710224 -> 139218443710128
	139218615508400 [label="Expert_Gate.fusion_modules.1.conv.bias
 (256)" fillcolor=lightblue]
	139218615508400 -> 139218443710224
	139218443710224 [label=AccumulateGrad]
	139218443710080 -> 139218443710032
	139218615508480 [label="Expert_Gate.fusion_modules.1.bn.weight
 (256)" fillcolor=lightblue]
	139218615508480 -> 139218443710080
	139218443710080 [label=AccumulateGrad]
	139218443709936 -> 139218443710032
	139218615508560 [label="Expert_Gate.fusion_modules.1.bn.bias
 (256)" fillcolor=lightblue]
	139218615508560 -> 139218443709936
	139218443709936 [label=AccumulateGrad]
	139218443709840 -> 139218443709744
	139218443709840 [label=UpsampleBilinear2DBackward0]
	139218443710368 -> 139218443709840
	139218443710368 [label=ReluBackward0]
	139218443709984 -> 139218443710368
	139218443709984 [label=ConvolutionBackward0]
	139218443731152 -> 139218443709984
	139218443731152 [label=ReluBackward0]
	139218443731824 -> 139218443731152
	139218443731824 [label=ConvolutionBackward0]
	139218443733648 -> 139218443731824
	139218443733648 [label=CatBackward0]
	139218443743536 -> 139218443733648
	139218443743536 [label=ReluBackward0]
	139218443743872 -> 139218443743536
	139218443743872 [label=NativeGroupNormBackward0]
	139218443744064 -> 139218443743872
	139218443744064 [label=ConvolutionBackward0]
	139218443744256 -> 139218443744064
	139218443744256 [label=MulBackward0]
	139218443744448 -> 139218443744256
	139218443744448 [label=CatBackward0]
	139218443744592 -> 139218443744448
	139218443744592 [label=ReluBackward0]
	139218443744688 -> 139218443744592
	139218443744688 [label=AddBackward0]
	139218443744784 -> 139218443744688
	139218443744784 [label=NativeGroupNormBackward0]
	139218443744928 -> 139218443744784
	139218443744928 [label=ConvolutionBackward0]
	139218443745120 -> 139218443744928
	139218443745120 [label=ReluBackward0]
	139218443745264 -> 139218443745120
	139218443745264 [label=NativeGroupNormBackward0]
	139218443745360 -> 139218443745264
	139218443745360 [label=ConvolutionBackward0]
	139218443745552 -> 139218443745360
	139218443745552 [label=ReluBackward0]
	139218443745696 -> 139218443745552
	139218443745696 [label=NativeGroupNormBackward0]
	139218443745792 -> 139218443745696
	139218443745792 [label=ConvolutionBackward0]
	139218443744736 -> 139218443745792
	139218443744736 [label=ReluBackward0]
	139218443746080 -> 139218443744736
	139218443746080 [label=AddBackward0]
	139218443746176 -> 139218443746080
	139218443746176 [label=NativeGroupNormBackward0]
	139218443746320 -> 139218443746176
	139218443746320 [label=ConvolutionBackward0]
	139218443746512 -> 139218443746320
	139218443746512 [label=ReluBackward0]
	139218443746656 -> 139218443746512
	139218443746656 [label=NativeGroupNormBackward0]
	139218443746752 -> 139218443746656
	139218443746752 [label=ConvolutionBackward0]
	139218443746944 -> 139218443746752
	139218443746944 [label=ReluBackward0]
	139218443747088 -> 139218443746944
	139218443747088 [label=NativeGroupNormBackward0]
	139218443747184 -> 139218443747088
	139218443747184 [label=ConvolutionBackward0]
	139218443746128 -> 139218443747184
	139218443746128 [label=ReluBackward0]
	139218443772112 -> 139218443746128
	139218443772112 [label=AddBackward0]
	139218443772208 -> 139218443772112
	139218443772208 [label=NativeGroupNormBackward0]
	139218443772352 -> 139218443772208
	139218443772352 [label=ConvolutionBackward0]
	139218443772544 -> 139218443772352
	139218443772544 [label=ReluBackward0]
	139218443772688 -> 139218443772544
	139218443772688 [label=NativeGroupNormBackward0]
	139218443772784 -> 139218443772688
	139218443772784 [label=ConvolutionBackward0]
	139218443772976 -> 139218443772784
	139218443772976 [label=ReluBackward0]
	139218443773120 -> 139218443772976
	139218443773120 [label=NativeGroupNormBackward0]
	139218443773216 -> 139218443773120
	139218443773216 [label=ConvolutionBackward0]
	139218443772160 -> 139218443773216
	139218443772160 [label=ReluBackward0]
	139218443773552 -> 139218443772160
	139218443773552 [label=AddBackward0]
	139218443773600 -> 139218443773552
	139218443773600 [label=NativeGroupNormBackward0]
	139218443773840 -> 139218443773600
	139218443773840 [label=ConvolutionBackward0]
	139218443774032 -> 139218443773840
	139218443774032 [label=ReluBackward0]
	139218443774176 -> 139218443774032
	139218443774176 [label=NativeGroupNormBackward0]
	139218443774224 -> 139218443774176
	139218443774224 [label=ConvolutionBackward0]
	139218443774512 -> 139218443774224
	139218443774512 [label=ReluBackward0]
	139218443774656 -> 139218443774512
	139218443774656 [label=NativeGroupNormBackward0]
	139218443774704 -> 139218443774656
	139218443774704 [label=ConvolutionBackward0]
	139218443731200 -> 139218443774704
	139218443774992 -> 139218443774704
	139218632287232 [label="Expert_Gate.expert_layers.0.layer2.0.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	139218632287232 -> 139218443774992
	139218443774992 [label=AccumulateGrad]
	139218443774560 -> 139218443774656
	139218632287312 [label="Expert_Gate.expert_layers.0.layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	139218632287312 -> 139218443774560
	139218443774560 [label=AccumulateGrad]
	139218443774800 -> 139218443774656
	139218632287392 [label="Expert_Gate.expert_layers.0.layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	139218632287392 -> 139218443774800
	139218443774800 [label=AccumulateGrad]
	139218443774464 -> 139218443774224
	139218632287632 [label="Expert_Gate.expert_layers.0.layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	139218632287632 -> 139218443774464
	139218443774464 [label=AccumulateGrad]
	139218443774080 -> 139218443774176
	139218632287552 [label="Expert_Gate.expert_layers.0.layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	139218632287552 -> 139218443774080
	139218443774080 [label=AccumulateGrad]
	139218443774320 -> 139218443774176
	139218632287712 [label="Expert_Gate.expert_layers.0.layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	139218632287712 -> 139218443774320
	139218443774320 [label=AccumulateGrad]
	139218443773984 -> 139218443773840
	139218632287872 [label="Expert_Gate.expert_layers.0.layer2.0.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	139218632287872 -> 139218443773984
	139218443773984 [label=AccumulateGrad]
	139218443773792 -> 139218443773600
	139218632287952 [label="Expert_Gate.expert_layers.0.layer2.0.bn3.weight
 (512)" fillcolor=lightblue]
	139218632287952 -> 139218443773792
	139218443773792 [label=AccumulateGrad]
	139218443773744 -> 139218443773600
	139218632288032 [label="Expert_Gate.expert_layers.0.layer2.0.bn3.bias
 (512)" fillcolor=lightblue]
	139218632288032 -> 139218443773744
	139218443773744 [label=AccumulateGrad]
	139218443773456 -> 139218443773552
	139218443773456 [label=NativeGroupNormBackward0]
	139218443774416 -> 139218443773456
	139218443774416 [label=ConvolutionBackward0]
	139218443731200 -> 139218443774416
	139218443774848 -> 139218443774416
	139218632286912 [label="Expert_Gate.expert_layers.0.layer2.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	139218632286912 -> 139218443774848
	139218443774848 [label=AccumulateGrad]
	139218443773936 -> 139218443773456
	139218632286992 [label="Expert_Gate.expert_layers.0.layer2.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	139218632286992 -> 139218443773936
	139218443773936 [label=AccumulateGrad]
	139218443773888 -> 139218443773456
	139218632287072 [label="Expert_Gate.expert_layers.0.layer2.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	139218632287072 -> 139218443773888
	139218443773888 [label=AccumulateGrad]
	139218443773360 -> 139218443773216
	139218632288192 [label="Expert_Gate.expert_layers.0.layer2.1.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	139218632288192 -> 139218443773360
	139218443773360 [label=AccumulateGrad]
	139218443773168 -> 139218443773120
	139218632288272 [label="Expert_Gate.expert_layers.0.layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	139218632288272 -> 139218443773168
	139218443773168 [label=AccumulateGrad]
	139218443773024 -> 139218443773120
	139218632288352 [label="Expert_Gate.expert_layers.0.layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	139218632288352 -> 139218443773024
	139218443773024 [label=AccumulateGrad]
	139218443772928 -> 139218443772784
	139218632288592 [label="Expert_Gate.expert_layers.0.layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	139218632288592 -> 139218443772928
	139218443772928 [label=AccumulateGrad]
	139218443772736 -> 139218443772688
	139218632288512 [label="Expert_Gate.expert_layers.0.layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	139218632288512 -> 139218443772736
	139218443772736 [label=AccumulateGrad]
	139218443772592 -> 139218443772688
	139218632288672 [label="Expert_Gate.expert_layers.0.layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	139218632288672 -> 139218443772592
	139218443772592 [label=AccumulateGrad]
	139218443772496 -> 139218443772352
	139218632288832 [label="Expert_Gate.expert_layers.0.layer2.1.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	139218632288832 -> 139218443772496
	139218443772496 [label=AccumulateGrad]
	139218443772304 -> 139218443772208
	139218632288912 [label="Expert_Gate.expert_layers.0.layer2.1.bn3.weight
 (512)" fillcolor=lightblue]
	139218632288912 -> 139218443772304
	139218443772304 [label=AccumulateGrad]
	139218443772256 -> 139218443772208
	139218632288992 [label="Expert_Gate.expert_layers.0.layer2.1.bn3.bias
 (512)" fillcolor=lightblue]
	139218632288992 -> 139218443772256
	139218443772256 [label=AccumulateGrad]
	139218443772160 -> 139218443772112
	139218443747280 -> 139218443747184
	139218632289152 [label="Expert_Gate.expert_layers.0.layer2.2.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	139218632289152 -> 139218443747280
	139218443747280 [label=AccumulateGrad]
	139218443747136 -> 139218443747088
	139218632289232 [label="Expert_Gate.expert_layers.0.layer2.2.bn1.weight
 (128)" fillcolor=lightblue]
	139218632289232 -> 139218443747136
	139218443747136 [label=AccumulateGrad]
	139218443746992 -> 139218443747088
	139218632289312 [label="Expert_Gate.expert_layers.0.layer2.2.bn1.bias
 (128)" fillcolor=lightblue]
	139218632289312 -> 139218443746992
	139218443746992 [label=AccumulateGrad]
	139218443746896 -> 139218443746752
	139218632289552 [label="Expert_Gate.expert_layers.0.layer2.2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	139218632289552 -> 139218443746896
	139218443746896 [label=AccumulateGrad]
	139218443746704 -> 139218443746656
	139218632289472 [label="Expert_Gate.expert_layers.0.layer2.2.bn2.weight
 (128)" fillcolor=lightblue]
	139218632289472 -> 139218443746704
	139218443746704 [label=AccumulateGrad]
	139218443746560 -> 139218443746656
	139218632289632 [label="Expert_Gate.expert_layers.0.layer2.2.bn2.bias
 (128)" fillcolor=lightblue]
	139218632289632 -> 139218443746560
	139218443746560 [label=AccumulateGrad]
	139218443746464 -> 139218443746320
	139218632289792 [label="Expert_Gate.expert_layers.0.layer2.2.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	139218632289792 -> 139218443746464
	139218443746464 [label=AccumulateGrad]
	139218443746272 -> 139218443746176
	139218632289872 [label="Expert_Gate.expert_layers.0.layer2.2.bn3.weight
 (512)" fillcolor=lightblue]
	139218632289872 -> 139218443746272
	139218443746272 [label=AccumulateGrad]
	139218443746224 -> 139218443746176
	139218632289952 [label="Expert_Gate.expert_layers.0.layer2.2.bn3.bias
 (512)" fillcolor=lightblue]
	139218632289952 -> 139218443746224
	139218443746224 [label=AccumulateGrad]
	139218443746128 -> 139218443746080
	139218443745984 -> 139218443745792
	139218632290112 [label="Expert_Gate.expert_layers.0.layer2.3.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	139218632290112 -> 139218443745984
	139218443745984 [label=AccumulateGrad]
	139218443745744 -> 139218443745696
	139218632290192 [label="Expert_Gate.expert_layers.0.layer2.3.bn1.weight
 (128)" fillcolor=lightblue]
	139218632290192 -> 139218443745744
	139218443745744 [label=AccumulateGrad]
	139218443745600 -> 139218443745696
	139218632470592 [label="Expert_Gate.expert_layers.0.layer2.3.bn1.bias
 (128)" fillcolor=lightblue]
	139218632470592 -> 139218443745600
	139218443745600 [label=AccumulateGrad]
	139218443745504 -> 139218443745360
	139218632470832 [label="Expert_Gate.expert_layers.0.layer2.3.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	139218632470832 -> 139218443745504
	139218443745504 [label=AccumulateGrad]
	139218443745312 -> 139218443745264
	139218632470752 [label="Expert_Gate.expert_layers.0.layer2.3.bn2.weight
 (128)" fillcolor=lightblue]
	139218632470752 -> 139218443745312
	139218443745312 [label=AccumulateGrad]
	139218443745168 -> 139218443745264
	139218632470912 [label="Expert_Gate.expert_layers.0.layer2.3.bn2.bias
 (128)" fillcolor=lightblue]
	139218632470912 -> 139218443745168
	139218443745168 [label=AccumulateGrad]
	139218443745072 -> 139218443744928
	139218632471072 [label="Expert_Gate.expert_layers.0.layer2.3.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	139218632471072 -> 139218443745072
	139218443745072 [label=AccumulateGrad]
	139218443744880 -> 139218443744784
	139218632471152 [label="Expert_Gate.expert_layers.0.layer2.3.bn3.weight
 (512)" fillcolor=lightblue]
	139218632471152 -> 139218443744880
	139218443744880 [label=AccumulateGrad]
	139218443744832 -> 139218443744784
	139218632471232 [label="Expert_Gate.expert_layers.0.layer2.3.bn3.bias
 (512)" fillcolor=lightblue]
	139218632471232 -> 139218443744832
	139218443744832 [label=AccumulateGrad]
	139218443744736 -> 139218443744688
	139218443744400 -> 139218443744256
	139218443744400 [label=AddBackward0]
	139218443744496 -> 139218443744400
	139218443744496 [label=TanhBackward0]
	139218443745024 -> 139218443744496
	139218443745024 [label=AddBackward0]
	139218443745408 -> 139218443745024
	139218443745408 [label=MulBackward0]
	139218443745840 -> 139218443745408
	139218443745840 [label=MulBackward0]
	139218443745888 -> 139218443745840
	139218443745888 [label=PowBackward0]
	139218443746848 -> 139218443745888
	139218443746848 [label=AddBackward0]
	139218443746608 -> 139218443746848
	139218443746608 [label=SumBackward1]
	139218443747040 -> 139218443746608
	139218443747040 [label=PowBackward0]
	139218443744448 -> 139218443747040
	139218443746368 -> 139218443745840
	139218615508640 [label="Expert_Gate.fusion_modules.2.alpha
 (1, 512, 1, 1)" fillcolor=lightblue]
	139218615508640 -> 139218443746368
	139218443746368 [label=AccumulateGrad]
	139218443745936 -> 139218443745408
	139218443745936 [label=DivBackward0]
	139218443746800 -> 139218443745936
	139218615508720 [label="Expert_Gate.fusion_modules.2.gamma
 (1, 512, 1, 1)" fillcolor=lightblue]
	139218615508720 -> 139218443746800
	139218443746800 [label=AccumulateGrad]
	139218443747232 -> 139218443745936
	139218443747232 [label=PowBackward0]
	139218443746416 -> 139218443747232
	139218443746416 [label=AddBackward0]
	139218443771968 -> 139218443746416
	139218443771968 [label=MeanBackward1]
	139218443772448 -> 139218443771968
	139218443772448 [label=PowBackward0]
	139218443745840 -> 139218443772448
	139218443745456 -> 139218443745024
	139218615508800 [label="Expert_Gate.fusion_modules.2.beta
 (1, 512, 1, 1)" fillcolor=lightblue]
	139218615508800 -> 139218443745456
	139218443745456 [label=AccumulateGrad]
	139218443744208 -> 139218443744064
	139218615668960 [label="Expert_Gate.fusion_modules.2.conv.weight
 (512, 512, 1, 1)" fillcolor=lightblue]
	139218615668960 -> 139218443744208
	139218443744208 [label=AccumulateGrad]
	139218443744160 -> 139218443744064
	139218615669040 [label="Expert_Gate.fusion_modules.2.conv.bias
 (512)" fillcolor=lightblue]
	139218615669040 -> 139218443744160
	139218443744160 [label=AccumulateGrad]
	139218443744016 -> 139218443743872
	139218615669120 [label="Expert_Gate.fusion_modules.2.bn.weight
 (512)" fillcolor=lightblue]
	139218615669120 -> 139218443744016
	139218443744016 [label=AccumulateGrad]
	139218443743584 -> 139218443743872
	139218615669200 [label="Expert_Gate.fusion_modules.2.bn.bias
 (512)" fillcolor=lightblue]
	139218615669200 -> 139218443743584
	139218443743584 [label=AccumulateGrad]
	139218443743968 -> 139218443733648
	139218443743968 [label=UpsampleBilinear2DBackward0]
	139218443744304 -> 139218443743968
	139218443744304 [label=ReluBackward0]
	139218443744640 -> 139218443744304
	139218443744640 [label=ConvolutionBackward0]
	139218443744544 -> 139218443744640
	139218443744544 [label=ReluBackward0]
	139218443745216 -> 139218443744544
	139218443745216 [label=ConvolutionBackward0]
	139218443746032 -> 139218443745216
	139218443746032 [label=CatBackward0]
	139218443772400 -> 139218443746032
	139218443772400 [label=ReluBackward0]
	139218443773264 -> 139218443772400
	139218443773264 [label=NativeGroupNormBackward0]
	139218443774368 -> 139218443773264
	139218443774368 [label=ConvolutionBackward0]
	139218443775232 -> 139218443774368
	139218443775232 [label=MulBackward0]
	139218443775136 -> 139218443775232
	139218443775136 [label=CatBackward0]
	139218443775376 -> 139218443775136
	139218443775376 [label=ReluBackward0]
	139218443775472 -> 139218443775376
	139218443775472 [label=AddBackward0]
	139218443775568 -> 139218443775472
	139218443775568 [label=NativeGroupNormBackward0]
	139218443775712 -> 139218443775568
	139218443775712 [label=ConvolutionBackward0]
	139218443775904 -> 139218443775712
	139218443775904 [label=ReluBackward0]
	139218443775952 -> 139218443775904
	139218443775952 [label=NativeGroupNormBackward0]
	139218712477904 -> 139218443775952
	139218712477904 [label=ConvolutionBackward0]
	139218712478096 -> 139218712477904
	139218712478096 [label=ReluBackward0]
	139218712478240 -> 139218712478096
	139218712478240 [label=NativeGroupNormBackward0]
	139218712478336 -> 139218712478240
	139218712478336 [label=ConvolutionBackward0]
	139218443775520 -> 139218712478336
	139218443775520 [label=ReluBackward0]
	139218712478624 -> 139218443775520
	139218712478624 [label=AddBackward0]
	139218712478720 -> 139218712478624
	139218712478720 [label=NativeGroupNormBackward0]
	139218712478864 -> 139218712478720
	139218712478864 [label=ConvolutionBackward0]
	139218712479056 -> 139218712478864
	139218712479056 [label=ReluBackward0]
	139218712479200 -> 139218712479056
	139218712479200 [label=NativeGroupNormBackward0]
	139218712479296 -> 139218712479200
	139218712479296 [label=ConvolutionBackward0]
	139218712479488 -> 139218712479296
	139218712479488 [label=ReluBackward0]
	139218712479632 -> 139218712479488
	139218712479632 [label=NativeGroupNormBackward0]
	139218712479728 -> 139218712479632
	139218712479728 [label=ConvolutionBackward0]
	139218712478672 -> 139218712479728
	139218712478672 [label=ReluBackward0]
	139218712480016 -> 139218712478672
	139218712480016 [label=AddBackward0]
	139218712480112 -> 139218712480016
	139218712480112 [label=NativeGroupNormBackward0]
	139218712480256 -> 139218712480112
	139218712480256 [label=ConvolutionBackward0]
	139218712480448 -> 139218712480256
	139218712480448 [label=ReluBackward0]
	139218712480592 -> 139218712480448
	139218712480592 [label=NativeGroupNormBackward0]
	139218712480688 -> 139218712480592
	139218712480688 [label=ConvolutionBackward0]
	139218712480880 -> 139218712480688
	139218712480880 [label=ReluBackward0]
	139218712481024 -> 139218712480880
	139218712481024 [label=NativeGroupNormBackward0]
	139218712481120 -> 139218712481024
	139218712481120 [label=ConvolutionBackward0]
	139218712480064 -> 139218712481120
	139218712480064 [label=ReluBackward0]
	139218712481408 -> 139218712480064
	139218712481408 [label=AddBackward0]
	139218712481504 -> 139218712481408
	139218712481504 [label=NativeGroupNormBackward0]
	139218712481648 -> 139218712481504
	139218712481648 [label=ConvolutionBackward0]
	139218712481744 -> 139218712481648
	139218712481744 [label=ReluBackward0]
	139218712490240 -> 139218712481744
	139218712490240 [label=NativeGroupNormBackward0]
	139218712490336 -> 139218712490240
	139218712490336 [label=ConvolutionBackward0]
	139218712490528 -> 139218712490336
	139218712490528 [label=ReluBackward0]
	139218712490672 -> 139218712490528
	139218712490672 [label=NativeGroupNormBackward0]
	139218712490768 -> 139218712490672
	139218712490768 [label=ConvolutionBackward0]
	139218712481456 -> 139218712490768
	139218712481456 [label=ReluBackward0]
	139218712491056 -> 139218712481456
	139218712491056 [label=AddBackward0]
	139218712491104 -> 139218712491056
	139218712491104 [label=NativeGroupNormBackward0]
	139218712491344 -> 139218712491104
	139218712491344 [label=ConvolutionBackward0]
	139218712491536 -> 139218712491344
	139218712491536 [label=ReluBackward0]
	139218712491680 -> 139218712491536
	139218712491680 [label=NativeGroupNormBackward0]
	139218712491728 -> 139218712491680
	139218712491728 [label=ConvolutionBackward0]
	139218712492016 -> 139218712491728
	139218712492016 [label=ReluBackward0]
	139218712492160 -> 139218712492016
	139218712492160 [label=NativeGroupNormBackward0]
	139218712492208 -> 139218712492160
	139218712492208 [label=ConvolutionBackward0]
	139218712490864 -> 139218712492208
	139218712490864 [label=ReluBackward0]
	139218712492592 -> 139218712490864
	139218712492592 [label=AddBackward0]
	139218712492640 -> 139218712492592
	139218712492640 [label=NativeGroupNormBackward0]
	139218712492880 -> 139218712492640
	139218712492880 [label=ConvolutionBackward0]
	139218712493072 -> 139218712492880
	139218712493072 [label=ReluBackward0]
	139218712493216 -> 139218712493072
	139218712493216 [label=NativeGroupNormBackward0]
	139218712493264 -> 139218712493216
	139218712493264 [label=ConvolutionBackward0]
	139218712493552 -> 139218712493264
	139218712493552 [label=ReluBackward0]
	139218712493696 -> 139218712493552
	139218712493696 [label=NativeGroupNormBackward0]
	139218712493744 -> 139218712493696
	139218712493744 [label=ConvolutionBackward0]
	139218443744592 -> 139218712493744
	139218712494032 -> 139218712493744
	139218632471712 [label="Expert_Gate.expert_layers.0.layer3.0.conv1.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	139218632471712 -> 139218712494032
	139218712494032 [label=AccumulateGrad]
	139218712493600 -> 139218712493696
	139218632471792 [label="Expert_Gate.expert_layers.0.layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	139218632471792 -> 139218712493600
	139218712493600 [label=AccumulateGrad]
	139218712493840 -> 139218712493696
	139218632471872 [label="Expert_Gate.expert_layers.0.layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	139218632471872 -> 139218712493840
	139218712493840 [label=AccumulateGrad]
	139218712493504 -> 139218712493264
	139218632472112 [label="Expert_Gate.expert_layers.0.layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	139218632472112 -> 139218712493504
	139218712493504 [label=AccumulateGrad]
	139218712493120 -> 139218712493216
	139218632472032 [label="Expert_Gate.expert_layers.0.layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	139218632472032 -> 139218712493120
	139218712493120 [label=AccumulateGrad]
	139218712493360 -> 139218712493216
	139218632472192 [label="Expert_Gate.expert_layers.0.layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	139218632472192 -> 139218712493360
	139218712493360 [label=AccumulateGrad]
	139218712493024 -> 139218712492880
	139218632472352 [label="Expert_Gate.expert_layers.0.layer3.0.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	139218632472352 -> 139218712493024
	139218712493024 [label=AccumulateGrad]
	139218712492832 -> 139218712492640
	139218632472432 [label="Expert_Gate.expert_layers.0.layer3.0.bn3.weight
 (1024)" fillcolor=lightblue]
	139218632472432 -> 139218712492832
	139218712492832 [label=AccumulateGrad]
	139218712492784 -> 139218712492640
	139218632472512 [label="Expert_Gate.expert_layers.0.layer3.0.bn3.bias
 (1024)" fillcolor=lightblue]
	139218632472512 -> 139218712492784
	139218712492784 [label=AccumulateGrad]
	139218712492400 -> 139218712492592
	139218712492400 [label=NativeGroupNormBackward0]
	139218712493456 -> 139218712492400
	139218712493456 [label=ConvolutionBackward0]
	139218443744592 -> 139218712493456
	139218712493888 -> 139218712493456
	139218632471392 [label="Expert_Gate.expert_layers.0.layer3.0.downsample.0.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	139218632471392 -> 139218712493888
	139218712493888 [label=AccumulateGrad]
	139218712492976 -> 139218712492400
	139218632471472 [label="Expert_Gate.expert_layers.0.layer3.0.downsample.1.weight
 (1024)" fillcolor=lightblue]
	139218632471472 -> 139218712492976
	139218712492976 [label=AccumulateGrad]
	139218712492928 -> 139218712492400
	139218632471552 [label="Expert_Gate.expert_layers.0.layer3.0.downsample.1.bias
 (1024)" fillcolor=lightblue]
	139218632471552 -> 139218712492928
	139218712492928 [label=AccumulateGrad]
	139218712492496 -> 139218712492208
	139218632472672 [label="Expert_Gate.expert_layers.0.layer3.1.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	139218632472672 -> 139218712492496
	139218712492496 [label=AccumulateGrad]
	139218712492064 -> 139218712492160
	139218632472752 [label="Expert_Gate.expert_layers.0.layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	139218632472752 -> 139218712492064
	139218712492064 [label=AccumulateGrad]
	139218712492304 -> 139218712492160
	139218632472832 [label="Expert_Gate.expert_layers.0.layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	139218632472832 -> 139218712492304
	139218712492304 [label=AccumulateGrad]
	139218712491968 -> 139218712491728
	139218632473072 [label="Expert_Gate.expert_layers.0.layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	139218632473072 -> 139218712491968
	139218712491968 [label=AccumulateGrad]
	139218712491584 -> 139218712491680
	139218632472992 [label="Expert_Gate.expert_layers.0.layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	139218632472992 -> 139218712491584
	139218712491584 [label=AccumulateGrad]
	139218712491824 -> 139218712491680
	139218632473152 [label="Expert_Gate.expert_layers.0.layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	139218632473152 -> 139218712491824
	139218712491824 [label=AccumulateGrad]
	139218712491488 -> 139218712491344
	139218632473312 [label="Expert_Gate.expert_layers.0.layer3.1.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	139218632473312 -> 139218712491488
	139218712491488 [label=AccumulateGrad]
	139218712491296 -> 139218712491104
	139218632473392 [label="Expert_Gate.expert_layers.0.layer3.1.bn3.weight
 (1024)" fillcolor=lightblue]
	139218632473392 -> 139218712491296
	139218712491296 [label=AccumulateGrad]
	139218712491248 -> 139218712491104
	139218632473472 [label="Expert_Gate.expert_layers.0.layer3.1.bn3.bias
 (1024)" fillcolor=lightblue]
	139218632473472 -> 139218712491248
	139218712491248 [label=AccumulateGrad]
	139218712490864 -> 139218712491056
	139218712490960 -> 139218712490768
	139218632473632 [label="Expert_Gate.expert_layers.0.layer3.2.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	139218632473632 -> 139218712490960
	139218712490960 [label=AccumulateGrad]
	139218712490720 -> 139218712490672
	139218632473712 [label="Expert_Gate.expert_layers.0.layer3.2.bn1.weight
 (256)" fillcolor=lightblue]
	139218632473712 -> 139218712490720
	139218712490720 [label=AccumulateGrad]
	139218712490576 -> 139218712490672
	139218632473792 [label="Expert_Gate.expert_layers.0.layer3.2.bn1.bias
 (256)" fillcolor=lightblue]
	139218632473792 -> 139218712490576
	139218712490576 [label=AccumulateGrad]
	139218712490480 -> 139218712490336
	139218632474032 [label="Expert_Gate.expert_layers.0.layer3.2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	139218632474032 -> 139218712490480
	139218712490480 [label=AccumulateGrad]
	139218712490288 -> 139218712490240
	139218632473952 [label="Expert_Gate.expert_layers.0.layer3.2.bn2.weight
 (256)" fillcolor=lightblue]
	139218632473952 -> 139218712490288
	139218712490288 [label=AccumulateGrad]
	139218712490144 -> 139218712490240
	139218632474112 [label="Expert_Gate.expert_layers.0.layer3.2.bn2.bias
 (256)" fillcolor=lightblue]
	139218632474112 -> 139218712490144
	139218712490144 [label=AccumulateGrad]
	139218712490096 -> 139218712481648
	139218632474272 [label="Expert_Gate.expert_layers.0.layer3.2.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	139218632474272 -> 139218712490096
	139218712490096 [label=AccumulateGrad]
	139218712481600 -> 139218712481504
	139218632474352 [label="Expert_Gate.expert_layers.0.layer3.2.bn3.weight
 (1024)" fillcolor=lightblue]
	139218632474352 -> 139218712481600
	139218712481600 [label=AccumulateGrad]
	139218712481552 -> 139218712481504
	139218632474432 [label="Expert_Gate.expert_layers.0.layer3.2.bn3.bias
 (1024)" fillcolor=lightblue]
	139218632474432 -> 139218712481552
	139218712481552 [label=AccumulateGrad]
	139218712481456 -> 139218712481408
	139218712481312 -> 139218712481120
	139218632130624 [label="Expert_Gate.expert_layers.0.layer3.3.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	139218632130624 -> 139218712481312
	139218712481312 [label=AccumulateGrad]
	139218712481072 -> 139218712481024
	139218632130704 [label="Expert_Gate.expert_layers.0.layer3.3.bn1.weight
 (256)" fillcolor=lightblue]
	139218632130704 -> 139218712481072
	139218712481072 [label=AccumulateGrad]
	139218712480928 -> 139218712481024
	139218632130784 [label="Expert_Gate.expert_layers.0.layer3.3.bn1.bias
 (256)" fillcolor=lightblue]
	139218632130784 -> 139218712480928
	139218712480928 [label=AccumulateGrad]
	139218712480832 -> 139218712480688
	139218632131024 [label="Expert_Gate.expert_layers.0.layer3.3.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	139218632131024 -> 139218712480832
	139218712480832 [label=AccumulateGrad]
	139218712480640 -> 139218712480592
	139218632130944 [label="Expert_Gate.expert_layers.0.layer3.3.bn2.weight
 (256)" fillcolor=lightblue]
	139218632130944 -> 139218712480640
	139218712480640 [label=AccumulateGrad]
	139218712480496 -> 139218712480592
	139218632131104 [label="Expert_Gate.expert_layers.0.layer3.3.bn2.bias
 (256)" fillcolor=lightblue]
	139218632131104 -> 139218712480496
	139218712480496 [label=AccumulateGrad]
	139218712480400 -> 139218712480256
	139218632131264 [label="Expert_Gate.expert_layers.0.layer3.3.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	139218632131264 -> 139218712480400
	139218712480400 [label=AccumulateGrad]
	139218712480208 -> 139218712480112
	139218632131344 [label="Expert_Gate.expert_layers.0.layer3.3.bn3.weight
 (1024)" fillcolor=lightblue]
	139218632131344 -> 139218712480208
	139218712480208 [label=AccumulateGrad]
	139218712480160 -> 139218712480112
	139218632131424 [label="Expert_Gate.expert_layers.0.layer3.3.bn3.bias
 (1024)" fillcolor=lightblue]
	139218632131424 -> 139218712480160
	139218712480160 [label=AccumulateGrad]
	139218712480064 -> 139218712480016
	139218712479920 -> 139218712479728
	139218632131584 [label="Expert_Gate.expert_layers.0.layer3.4.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	139218632131584 -> 139218712479920
	139218712479920 [label=AccumulateGrad]
	139218712479680 -> 139218712479632
	139218632131664 [label="Expert_Gate.expert_layers.0.layer3.4.bn1.weight
 (256)" fillcolor=lightblue]
	139218632131664 -> 139218712479680
	139218712479680 [label=AccumulateGrad]
	139218712479536 -> 139218712479632
	139218632131744 [label="Expert_Gate.expert_layers.0.layer3.4.bn1.bias
 (256)" fillcolor=lightblue]
	139218632131744 -> 139218712479536
	139218712479536 [label=AccumulateGrad]
	139218712479440 -> 139218712479296
	139218632131984 [label="Expert_Gate.expert_layers.0.layer3.4.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	139218632131984 -> 139218712479440
	139218712479440 [label=AccumulateGrad]
	139218712479248 -> 139218712479200
	139218632131904 [label="Expert_Gate.expert_layers.0.layer3.4.bn2.weight
 (256)" fillcolor=lightblue]
	139218632131904 -> 139218712479248
	139218712479248 [label=AccumulateGrad]
	139218712479104 -> 139218712479200
	139218632132064 [label="Expert_Gate.expert_layers.0.layer3.4.bn2.bias
 (256)" fillcolor=lightblue]
	139218632132064 -> 139218712479104
	139218712479104 [label=AccumulateGrad]
	139218712479008 -> 139218712478864
	139218632132224 [label="Expert_Gate.expert_layers.0.layer3.4.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	139218632132224 -> 139218712479008
	139218712479008 [label=AccumulateGrad]
	139218712478816 -> 139218712478720
	139218632132304 [label="Expert_Gate.expert_layers.0.layer3.4.bn3.weight
 (1024)" fillcolor=lightblue]
	139218632132304 -> 139218712478816
	139218712478816 [label=AccumulateGrad]
	139218712478768 -> 139218712478720
	139218632132384 [label="Expert_Gate.expert_layers.0.layer3.4.bn3.bias
 (1024)" fillcolor=lightblue]
	139218632132384 -> 139218712478768
	139218712478768 [label=AccumulateGrad]
	139218712478672 -> 139218712478624
	139218712478528 -> 139218712478336
	139218632132544 [label="Expert_Gate.expert_layers.0.layer3.5.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	139218632132544 -> 139218712478528
	139218712478528 [label=AccumulateGrad]
	139218712478288 -> 139218712478240
	139218632132624 [label="Expert_Gate.expert_layers.0.layer3.5.bn1.weight
 (256)" fillcolor=lightblue]
	139218632132624 -> 139218712478288
	139218712478288 [label=AccumulateGrad]
	139218712478144 -> 139218712478240
	139218632132704 [label="Expert_Gate.expert_layers.0.layer3.5.bn1.bias
 (256)" fillcolor=lightblue]
	139218632132704 -> 139218712478144
	139218712478144 [label=AccumulateGrad]
	139218712478048 -> 139218712477904
	139218632132944 [label="Expert_Gate.expert_layers.0.layer3.5.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	139218632132944 -> 139218712478048
	139218712478048 [label=AccumulateGrad]
	139218712477856 -> 139218443775952
	139218632132864 [label="Expert_Gate.expert_layers.0.layer3.5.bn2.weight
 (256)" fillcolor=lightblue]
	139218632132864 -> 139218712477856
	139218712477856 [label=AccumulateGrad]
	139218712477760 -> 139218443775952
	139218632133024 [label="Expert_Gate.expert_layers.0.layer3.5.bn2.bias
 (256)" fillcolor=lightblue]
	139218632133024 -> 139218712477760
	139218712477760 [label=AccumulateGrad]
	139218443775856 -> 139218443775712
	139218632133184 [label="Expert_Gate.expert_layers.0.layer3.5.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	139218632133184 -> 139218443775856
	139218443775856 [label=AccumulateGrad]
	139218443775664 -> 139218443775568
	139218632133264 [label="Expert_Gate.expert_layers.0.layer3.5.bn3.weight
 (1024)" fillcolor=lightblue]
	139218632133264 -> 139218443775664
	139218443775664 [label=AccumulateGrad]
	139218443775616 -> 139218443775568
	139218632133344 [label="Expert_Gate.expert_layers.0.layer3.5.bn3.bias
 (1024)" fillcolor=lightblue]
	139218632133344 -> 139218443775616
	139218443775616 [label=AccumulateGrad]
	139218443775520 -> 139218443775472
	139218443775184 -> 139218443775232
	139218443775184 [label=AddBackward0]
	139218443775280 -> 139218443775184
	139218443775280 [label=TanhBackward0]
	139218443775808 -> 139218443775280
	139218443775808 [label=AddBackward0]
	139218443775328 -> 139218443775808
	139218443775328 [label=MulBackward0]
	139218712478384 -> 139218443775328
	139218712478384 [label=MulBackward0]
	139218712478432 -> 139218712478384
	139218712478432 [label=PowBackward0]
	139218712479392 -> 139218712478432
	139218712479392 [label=AddBackward0]
	139218712479152 -> 139218712479392
	139218712479152 [label=SumBackward1]
	139218712479776 -> 139218712479152
	139218712479776 [label=PowBackward0]
	139218443775136 -> 139218712479776
	139218712478912 -> 139218712478384
	139218615669280 [label="Expert_Gate.fusion_modules.3.alpha
 (1, 1024, 1, 1)" fillcolor=lightblue]
	139218615669280 -> 139218712478912
	139218712478912 [label=AccumulateGrad]
	139218712478480 -> 139218443775328
	139218712478480 [label=DivBackward0]
	139218712479344 -> 139218712478480
	139218615669360 [label="Expert_Gate.fusion_modules.3.gamma
 (1, 1024, 1, 1)" fillcolor=lightblue]
	139218615669360 -> 139218712479344
	139218712479344 [label=AccumulateGrad]
	139218712479872 -> 139218712478480
	139218712479872 [label=PowBackward0]
	139218712478960 -> 139218712479872
	139218712478960 [label=AddBackward0]
	139218712479824 -> 139218712478960
	139218712479824 [label=MeanBackward1]
	139218712480784 -> 139218712479824
	139218712480784 [label=PowBackward0]
	139218712478384 -> 139218712480784
	139218712477952 -> 139218443775808
	139218615669440 [label="Expert_Gate.fusion_modules.3.beta
 (1, 1024, 1, 1)" fillcolor=lightblue]
	139218615669440 -> 139218712477952
	139218712477952 [label=AccumulateGrad]
	139218443774944 -> 139218443774368
	139218615669760 [label="Expert_Gate.fusion_modules.3.conv.weight
 (1024, 1024, 1, 1)" fillcolor=lightblue]
	139218615669760 -> 139218443774944
	139218443774944 [label=AccumulateGrad]
	139218443773504 -> 139218443774368
	139218615669840 [label="Expert_Gate.fusion_modules.3.conv.bias
 (1024)" fillcolor=lightblue]
	139218615669840 -> 139218443773504
	139218443773504 [label=AccumulateGrad]
	139218443773072 -> 139218443773264
	139218615669920 [label="Expert_Gate.fusion_modules.3.bn.weight
 (1024)" fillcolor=lightblue]
	139218615669920 -> 139218443773072
	139218443773072 [label=AccumulateGrad]
	139218443772640 -> 139218443773264
	139218615670000 [label="Expert_Gate.fusion_modules.3.bn.bias
 (1024)" fillcolor=lightblue]
	139218615670000 -> 139218443772640
	139218443772640 [label=AccumulateGrad]
	139218443772880 -> 139218443746032
	139218443772880 [label=UpsampleBilinear2DBackward0]
	139218443774608 -> 139218443772880
	139218443774608 [label=ReluBackward0]
	139218443775424 -> 139218443774608
	139218443775424 [label=NativeGroupNormBackward0]
	139218443775760 -> 139218443775424
	139218443775760 [label=ConvolutionBackward0]
	139218712478576 -> 139218443775760
	139218712478576 [label=MulBackward0]
	139218712479584 -> 139218712478576
	139218712479584 [label=CatBackward0]
	139218712480976 -> 139218712479584
	139218712480976 [label=ReluBackward0]
	139218712481216 -> 139218712480976
	139218712481216 [label=AddBackward0]
	139218712481360 -> 139218712481216
	139218712481360 [label=NativeGroupNormBackward0]
	139218712490192 -> 139218712481360
	139218712490192 [label=ConvolutionBackward0]
	139218712491392 -> 139218712490192
	139218712491392 [label=ReluBackward0]
	139218712491440 -> 139218712491392
	139218712491440 [label=NativeGroupNormBackward0]
	139218712491872 -> 139218712491440
	139218712491872 [label=ConvolutionBackward0]
	139218712492112 -> 139218712491872
	139218712492112 [label=ReluBackward0]
	139218712492544 -> 139218712492112
	139218712492544 [label=NativeGroupNormBackward0]
	139218712493648 -> 139218712492544
	139218712493648 [label=ConvolutionBackward0]
	139218712481264 -> 139218712493648
	139218712481264 [label=ReluBackward0]
	139218712502624 -> 139218712481264
	139218712502624 [label=AddBackward0]
	139218712502720 -> 139218712502624
	139218712502720 [label=NativeGroupNormBackward0]
	139218712502864 -> 139218712502720
	139218712502864 [label=ConvolutionBackward0]
	139218712503056 -> 139218712502864
	139218712503056 [label=ReluBackward0]
	139218712503200 -> 139218712503056
	139218712503200 [label=NativeGroupNormBackward0]
	139218712503296 -> 139218712503200
	139218712503296 [label=ConvolutionBackward0]
	139218712503488 -> 139218712503296
	139218712503488 [label=ReluBackward0]
	139218712503632 -> 139218712503488
	139218712503632 [label=NativeGroupNormBackward0]
	139218712503728 -> 139218712503632
	139218712503728 [label=ConvolutionBackward0]
	139218712502672 -> 139218712503728
	139218712502672 [label=ReluBackward0]
	139218712504016 -> 139218712502672
	139218712504016 [label=AddBackward0]
	139218712504112 -> 139218712504016
	139218712504112 [label=NativeGroupNormBackward0]
	139218712504256 -> 139218712504112
	139218712504256 [label=ConvolutionBackward0]
	139218712504448 -> 139218712504256
	139218712504448 [label=ReluBackward0]
	139218712504592 -> 139218712504448
	139218712504592 [label=NativeGroupNormBackward0]
	139218712504688 -> 139218712504592
	139218712504688 [label=ConvolutionBackward0]
	139218712504880 -> 139218712504688
	139218712504880 [label=ReluBackward0]
	139218712505024 -> 139218712504880
	139218712505024 [label=NativeGroupNormBackward0]
	139218712505120 -> 139218712505024
	139218712505120 [label=ConvolutionBackward0]
	139218443775376 -> 139218712505120
	139218712505312 -> 139218712505120
	139218632133824 [label="Expert_Gate.expert_layers.0.layer4.0.conv1.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	139218632133824 -> 139218712505312
	139218712505312 [label=AccumulateGrad]
	139218712505072 -> 139218712505024
	139218632133904 [label="Expert_Gate.expert_layers.0.layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	139218632133904 -> 139218712505072
	139218712505072 [label=AccumulateGrad]
	139218712504928 -> 139218712505024
	139218632133984 [label="Expert_Gate.expert_layers.0.layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	139218632133984 -> 139218712504928
	139218712504928 [label=AccumulateGrad]
	139218712504832 -> 139218712504688
	139218632134224 [label="Expert_Gate.expert_layers.0.layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	139218632134224 -> 139218712504832
	139218712504832 [label=AccumulateGrad]
	139218712504640 -> 139218712504592
	139218632134144 [label="Expert_Gate.expert_layers.0.layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	139218632134144 -> 139218712504640
	139218712504640 [label=AccumulateGrad]
	139218712504496 -> 139218712504592
	139218632134304 [label="Expert_Gate.expert_layers.0.layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	139218632134304 -> 139218712504496
	139218712504496 [label=AccumulateGrad]
	139218712504400 -> 139218712504256
	139218632134464 [label="Expert_Gate.expert_layers.0.layer4.0.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	139218632134464 -> 139218712504400
	139218712504400 [label=AccumulateGrad]
	139218712504208 -> 139218712504112
	139218632134544 [label="Expert_Gate.expert_layers.0.layer4.0.bn3.weight
 (2048)" fillcolor=lightblue]
	139218632134544 -> 139218712504208
	139218712504208 [label=AccumulateGrad]
	139218712504160 -> 139218712504112
	139218615504960 [label="Expert_Gate.expert_layers.0.layer4.0.bn3.bias
 (2048)" fillcolor=lightblue]
	139218615504960 -> 139218712504160
	139218712504160 [label=AccumulateGrad]
	139218712504064 -> 139218712504016
	139218712504064 [label=NativeGroupNormBackward0]
	139218712504784 -> 139218712504064
	139218712504784 [label=ConvolutionBackward0]
	139218443775376 -> 139218712504784
	139218712505168 -> 139218712504784
	139218632133504 [label="Expert_Gate.expert_layers.0.layer4.0.downsample.0.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	139218632133504 -> 139218712505168
	139218712505168 [label=AccumulateGrad]
	139218712504352 -> 139218712504064
	139218632133584 [label="Expert_Gate.expert_layers.0.layer4.0.downsample.1.weight
 (2048)" fillcolor=lightblue]
	139218632133584 -> 139218712504352
	139218712504352 [label=AccumulateGrad]
	139218712504304 -> 139218712504064
	139218632133664 [label="Expert_Gate.expert_layers.0.layer4.0.downsample.1.bias
 (2048)" fillcolor=lightblue]
	139218632133664 -> 139218712504304
	139218712504304 [label=AccumulateGrad]
	139218712503920 -> 139218712503728
	139218615505120 [label="Expert_Gate.expert_layers.0.layer4.1.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	139218615505120 -> 139218712503920
	139218712503920 [label=AccumulateGrad]
	139218712503680 -> 139218712503632
	139218615505200 [label="Expert_Gate.expert_layers.0.layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	139218615505200 -> 139218712503680
	139218712503680 [label=AccumulateGrad]
	139218712503536 -> 139218712503632
	139218615505280 [label="Expert_Gate.expert_layers.0.layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	139218615505280 -> 139218712503536
	139218712503536 [label=AccumulateGrad]
	139218712503440 -> 139218712503296
	139218615505520 [label="Expert_Gate.expert_layers.0.layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	139218615505520 -> 139218712503440
	139218712503440 [label=AccumulateGrad]
	139218712503248 -> 139218712503200
	139218615505440 [label="Expert_Gate.expert_layers.0.layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	139218615505440 -> 139218712503248
	139218712503248 [label=AccumulateGrad]
	139218712503104 -> 139218712503200
	139218615505600 [label="Expert_Gate.expert_layers.0.layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	139218615505600 -> 139218712503104
	139218712503104 [label=AccumulateGrad]
	139218712503008 -> 139218712502864
	139218615505760 [label="Expert_Gate.expert_layers.0.layer4.1.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	139218615505760 -> 139218712503008
	139218712503008 [label=AccumulateGrad]
	139218712502816 -> 139218712502720
	139218615505840 [label="Expert_Gate.expert_layers.0.layer4.1.bn3.weight
 (2048)" fillcolor=lightblue]
	139218615505840 -> 139218712502816
	139218712502816 [label=AccumulateGrad]
	139218712502768 -> 139218712502720
	139218615505920 [label="Expert_Gate.expert_layers.0.layer4.1.bn3.bias
 (2048)" fillcolor=lightblue]
	139218615505920 -> 139218712502768
	139218712502768 [label=AccumulateGrad]
	139218712502672 -> 139218712502624
	139218712502432 -> 139218712493648
	139218615506080 [label="Expert_Gate.expert_layers.0.layer4.2.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	139218615506080 -> 139218712502432
	139218712502432 [label=AccumulateGrad]
	139218712493984 -> 139218712492544
	139218615506160 [label="Expert_Gate.expert_layers.0.layer4.2.bn1.weight
 (512)" fillcolor=lightblue]
	139218615506160 -> 139218712493984
	139218712493984 [label=AccumulateGrad]
	139218712493408 -> 139218712492544
	139218615506240 [label="Expert_Gate.expert_layers.0.layer4.2.bn1.bias
 (512)" fillcolor=lightblue]
	139218615506240 -> 139218712493408
	139218712493408 [label=AccumulateGrad]
	139218712492352 -> 139218712491872
	139218615506480 [label="Expert_Gate.expert_layers.0.layer4.2.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	139218615506480 -> 139218712492352
	139218712492352 [label=AccumulateGrad]
	139218712491920 -> 139218712491440
	139218615506400 [label="Expert_Gate.expert_layers.0.layer4.2.bn2.weight
 (512)" fillcolor=lightblue]
	139218615506400 -> 139218712491920
	139218712491920 [label=AccumulateGrad]
	139218712491200 -> 139218712491440
	139218615506560 [label="Expert_Gate.expert_layers.0.layer4.2.bn2.bias
 (512)" fillcolor=lightblue]
	139218615506560 -> 139218712491200
	139218712491200 [label=AccumulateGrad]
	139218712490624 -> 139218712490192
	139218615506720 [label="Expert_Gate.expert_layers.0.layer4.2.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	139218615506720 -> 139218712490624
	139218712490624 [label=AccumulateGrad]
	139218712490384 -> 139218712481360
	139218615506800 [label="Expert_Gate.expert_layers.0.layer4.2.bn3.weight
 (2048)" fillcolor=lightblue]
	139218615506800 -> 139218712490384
	139218712490384 [label=AccumulateGrad]
	139218712490432 -> 139218712481360
	139218615506880 [label="Expert_Gate.expert_layers.0.layer4.2.bn3.bias
 (2048)" fillcolor=lightblue]
	139218615506880 -> 139218712490432
	139218712490432 [label=AccumulateGrad]
	139218712481264 -> 139218712481216
	139218712480736 -> 139218712478576
	139218712480736 [label=AddBackward0]
	139218712481696 -> 139218712480736
	139218712481696 [label=TanhBackward0]
	139218712490816 -> 139218712481696
	139218712490816 [label=AddBackward0]
	139218712491632 -> 139218712490816
	139218712491632 [label=MulBackward0]
	139218712492736 -> 139218712491632
	139218712492736 [label=MulBackward0]
	139218712502528 -> 139218712492736
	139218712502528 [label=PowBackward0]
	139218712503392 -> 139218712502528
	139218712503392 [label=AddBackward0]
	139218712503152 -> 139218712503392
	139218712503152 [label=SumBackward1]
	139218712503776 -> 139218712503152
	139218712503776 [label=PowBackward0]
	139218712479584 -> 139218712503776
	139218712502912 -> 139218712492736
	139218615670080 [label="Expert_Gate.fusion_modules.4.alpha
 (1, 2048, 1, 1)" fillcolor=lightblue]
	139218615670080 -> 139218712502912
	139218712502912 [label=AccumulateGrad]
	139218712493168 -> 139218712491632
	139218712493168 [label=DivBackward0]
	139218712503344 -> 139218712493168
	139218615670160 [label="Expert_Gate.fusion_modules.4.gamma
 (1, 2048, 1, 1)" fillcolor=lightblue]
	139218615670160 -> 139218712503344
	139218712503344 [label=AccumulateGrad]
	139218712503872 -> 139218712493168
	139218712503872 [label=PowBackward0]
	139218712502960 -> 139218712503872
	139218712502960 [label=AddBackward0]
	139218712503824 -> 139218712502960
	139218712503824 [label=MeanBackward1]
	139218712505264 -> 139218712503824
	139218712505264 [label=PowBackward0]
	139218712492736 -> 139218712505264
	139218712492448 -> 139218712490816
	139218615670240 [label="Expert_Gate.fusion_modules.4.beta
 (1, 2048, 1, 1)" fillcolor=lightblue]
	139218615670240 -> 139218712492448
	139218712492448 [label=AccumulateGrad]
	139218712477808 -> 139218443775760
	139218615670560 [label="Expert_Gate.fusion_modules.4.conv.weight
 (2048, 2048, 1, 1)" fillcolor=lightblue]
	139218615670560 -> 139218712477808
	139218712477808 [label=AccumulateGrad]
	139218712478192 -> 139218443775760
	139218615670640 [label="Expert_Gate.fusion_modules.4.conv.bias
 (2048)" fillcolor=lightblue]
	139218615670640 -> 139218712478192
	139218712478192 [label=AccumulateGrad]
	139218443773312 -> 139218443775424
	139218615670720 [label="Expert_Gate.fusion_modules.4.bn.weight
 (2048)" fillcolor=lightblue]
	139218615670720 -> 139218443773312
	139218443773312 [label=AccumulateGrad]
	139218712478000 -> 139218443775424
	139218615670800 [label="Expert_Gate.fusion_modules.4.bn.bias
 (2048)" fillcolor=lightblue]
	139218615670800 -> 139218712478000
	139218712478000 [label=AccumulateGrad]
	139218443772064 -> 139218443745216
	139218712809616 [label="up_concat4.conv1.weight
 (512, 3072, 3, 3)" fillcolor=lightblue]
	139218712809616 -> 139218443772064
	139218443772064 [label=AccumulateGrad]
	139218443744976 -> 139218443744640
	139218712809776 [label="up_concat4.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	139218712809776 -> 139218443744976
	139218443744976 [label=AccumulateGrad]
	139218443732640 -> 139218443731824
	139218712809936 [label="up_concat3.conv1.weight
 (256, 1024, 3, 3)" fillcolor=lightblue]
	139218712809936 -> 139218443732640
	139218443732640 [label=AccumulateGrad]
	139218443731584 -> 139218443709984
	139218712810096 [label="up_concat3.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	139218712810096 -> 139218443731584
	139218443731584 [label=AccumulateGrad]
	139218443709264 -> 139218443708976
	139218712810256 [label="up_concat2.conv1.weight
 (128, 512, 3, 3)" fillcolor=lightblue]
	139218712810256 -> 139218443709264
	139218443709264 [label=AccumulateGrad]
	139218443708784 -> 139218443708496
	139218712810416 [label="up_concat2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	139218712810416 -> 139218443708784
	139218443708784 [label=AccumulateGrad]
	139218443707488 -> 139218443707440
	139218712810576 [label="up_concat1.conv1.weight
 (64, 192, 3, 3)" fillcolor=lightblue]
	139218712810576 -> 139218443707488
	139218443707488 [label=AccumulateGrad]
	139218443707248 -> 139218443707200
	139218712810736 [label="up_concat1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139218712810736 -> 139218443707248
	139218443707248 [label=AccumulateGrad]
	139218443706864 -> 139218443706816
	139218712772256 [label="up_conv.1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139218712772256 -> 139218443706864
	139218443706864 [label=AccumulateGrad]
	139218443706720 -> 139218443706816
	139218712772336 [label="up_conv.1.bias
 (64)" fillcolor=lightblue]
	139218712772336 -> 139218443706720
	139218443706720 [label=AccumulateGrad]
	139218443706576 -> 139218443706528
	139218712772176 [label="up_conv.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139218712772176 -> 139218443706576
	139218443706576 [label=AccumulateGrad]
	139218443706432 -> 139218443706528
	139218712772416 [label="up_conv.3.bias
 (64)" fillcolor=lightblue]
	139218712772416 -> 139218443706432
	139218443706432 [label=AccumulateGrad]
	139218615517040 -> 139218615516992
	139218615670880 [label="final.0.0.weight
 (64)" fillcolor=lightblue]
	139218615670880 -> 139218615517040
	139218615517040 [label=AccumulateGrad]
	139218615516560 -> 139218615516992
	139218615670960 [label="final.0.0.bias
 (64)" fillcolor=lightblue]
	139218615670960 -> 139218615516560
	139218615516560 [label=AccumulateGrad]
	139218615516896 -> 139218615516848
	139218615671120 [label="final.0.2.weight
 (8, 64, 3, 3)" fillcolor=lightblue]
	139218615671120 -> 139218615516896
	139218615516896 [label=AccumulateGrad]
	139218615516800 -> 139218615516848
	139218615671200 [label="final.0.2.bias
 (8)" fillcolor=lightblue]
	139218615671200 -> 139218615516800
	139218615516800 [label=AccumulateGrad]
	139218615516848 -> 139218443670928
	139218443671968 [label="
 (1, 5, 384, 512)" fillcolor=darkolivegreen1]
	139218615516752 [label=ConvolutionBackward0]
	139218615517136 -> 139218615516752
	139218615517136 [label=ReluBackward0]
	139218443707056 -> 139218615517136
	139218443707056 [label=NativeGroupNormBackward0]
	139218443707008 -> 139218443707056
	139218443707008 [label=ReluBackward0]
	139218443707968 -> 139218443707008
	139218443707968 [label=ConvolutionBackward0]
	139218443707776 -> 139218443707968
	139218443707776 [label=ReluBackward0]
	139218443709648 -> 139218443707776
	139218443709648 [label=ConvolutionBackward0]
	139218443709888 -> 139218443709648
	139218443709888 [label=UpsampleBilinear2DBackward0]
	139218443707344 -> 139218443709888
	139218443707344 [label=ReluBackward0]
	139218443732256 -> 139218443707344
	139218443732256 [label=ConvolutionBackward0]
	139218443731248 -> 139218443732256
	139218443731248 [label=ReluBackward0]
	139218443743920 -> 139218443731248
	139218443743920 [label=ConvolutionBackward0]
	139218443745648 -> 139218443743920
	139218443745648 [label=CatBackward0]
	139218443773696 -> 139218443745648
	139218443773696 [label=ReluBackward0]
	139218443772832 -> 139218443773696
	139218443772832 [label=NativeGroupNormBackward0]
	139218712481168 -> 139218443772832
	139218712481168 [label=ConvolutionBackward0]
	139218712480304 -> 139218712481168
	139218712480304 [label=MulBackward0]
	139218712491008 -> 139218712480304
	139218712491008 [label=CatBackward0]
	139218443708448 -> 139218712491008
	139218712490912 -> 139218712480304
	139218712490912 [label=AddBackward0]
	139218712502480 -> 139218712490912
	139218712502480 [label=TanhBackward0]
	139218712505408 -> 139218712502480
	139218712505408 [label=AddBackward0]
	139218712504544 -> 139218712505408
	139218712504544 [label=MulBackward0]
	139218712505216 -> 139218712504544
	139218712505216 [label=MulBackward0]
	139218712505552 -> 139218712505216
	139218712505552 [label=PowBackward0]
	139218712505648 -> 139218712505552
	139218712505648 [label=AddBackward0]
	139218712505744 -> 139218712505648
	139218712505744 [label=SumBackward1]
	139218712505840 -> 139218712505744
	139218712505840 [label=PowBackward0]
	139218712491008 -> 139218712505840
	139218443709168 -> 139218712505216
	139218712505360 -> 139218712504544
	139218712505360 [label=DivBackward0]
	139218443709408 -> 139218712505360
	139218712505696 -> 139218712505360
	139218712505696 [label=PowBackward0]
	139218712505936 -> 139218712505696
	139218712505936 [label=AddBackward0]
	139218712505456 -> 139218712505936
	139218712505456 [label=MeanBackward1]
	139218712506032 -> 139218712505456
	139218712506032 [label=PowBackward0]
	139218712505216 -> 139218712506032
	139218443708880 -> 139218712505408
	139218443708064 -> 139218712481168
	139218443708016 -> 139218712481168
	139218443707872 -> 139218443772832
	139218443707728 -> 139218443772832
	139218443772016 -> 139218443745648
	139218443772016 [label=UpsampleBilinear2DBackward0]
	139218712490048 -> 139218443772016
	139218712490048 [label=ReluBackward0]
	139218712479968 -> 139218712490048
	139218712479968 [label=ConvolutionBackward0]
	139218712503584 -> 139218712479968
	139218712503584 [label=ReluBackward0]
	139218712505600 -> 139218712503584
	139218712505600 [label=ConvolutionBackward0]
	139218712505888 -> 139218712505600
	139218712505888 [label=CatBackward0]
	139218712506128 -> 139218712505888
	139218712506128 [label=ReluBackward0]
	139218712506176 -> 139218712506128
	139218712506176 [label=NativeGroupNormBackward0]
	139218712506272 -> 139218712506176
	139218712506272 [label=ConvolutionBackward0]
	139218712506320 -> 139218712506272
	139218712506320 [label=MulBackward0]
	139218712580256 -> 139218712506320
	139218712580256 [label=CatBackward0]
	139218443731200 -> 139218712580256
	139218712580208 -> 139218712506320
	139218712580208 [label=AddBackward0]
	139218712580304 -> 139218712580208
	139218712580304 [label=TanhBackward0]
	139218712580496 -> 139218712580304
	139218712580496 [label=AddBackward0]
	139218712580592 -> 139218712580496
	139218712580592 [label=MulBackward0]
	139218712580688 -> 139218712580592
	139218712580688 [label=MulBackward0]
	139218712580832 -> 139218712580688
	139218712580832 [label=PowBackward0]
	139218712580928 -> 139218712580832
	139218712580928 [label=AddBackward0]
	139218712581024 -> 139218712580928
	139218712581024 [label=SumBackward1]
	139218712581120 -> 139218712581024
	139218712581120 [label=PowBackward0]
	139218712580256 -> 139218712581120
	139218443732976 -> 139218712580688
	139218712580640 -> 139218712580592
	139218712580640 [label=DivBackward0]
	139218443733408 -> 139218712580640
	139218712580976 -> 139218712580640
	139218712580976 [label=PowBackward0]
	139218712581216 -> 139218712580976
	139218712581216 [label=AddBackward0]
	139218712580736 -> 139218712581216
	139218712580736 [label=MeanBackward1]
	139218712581312 -> 139218712580736
	139218712581312 [label=PowBackward0]
	139218712580688 -> 139218712581312
	139218443732064 -> 139218712580496
	139218443710272 -> 139218712506272
	139218443710224 -> 139218712506272
	139218443710080 -> 139218712506176
	139218443709936 -> 139218712506176
	139218712505984 -> 139218712505888
	139218712505984 [label=UpsampleBilinear2DBackward0]
	139218712506080 -> 139218712505984
	139218712506080 [label=ReluBackward0]
	139218712505504 -> 139218712506080
	139218712505504 [label=ConvolutionBackward0]
	139218712580544 -> 139218712505504
	139218712580544 [label=ReluBackward0]
	139218712580880 -> 139218712580544
	139218712580880 [label=ConvolutionBackward0]
	139218712581168 -> 139218712580880
	139218712581168 [label=CatBackward0]
	139218712581408 -> 139218712581168
	139218712581408 [label=ReluBackward0]
	139218712581456 -> 139218712581408
	139218712581456 [label=NativeGroupNormBackward0]
	139218712581552 -> 139218712581456
	139218712581552 [label=ConvolutionBackward0]
	139218712581648 -> 139218712581552
	139218712581648 [label=MulBackward0]
	139218712581744 -> 139218712581648
	139218712581744 [label=CatBackward0]
	139218443744592 -> 139218712581744
	139218712581696 -> 139218712581648
	139218712581696 [label=AddBackward0]
	139218712581792 -> 139218712581696
	139218712581792 [label=TanhBackward0]
	139218712581984 -> 139218712581792
	139218712581984 [label=AddBackward0]
	139218712582080 -> 139218712581984
	139218712582080 [label=MulBackward0]
	139218712582176 -> 139218712582080
	139218712582176 [label=MulBackward0]
	139218712582320 -> 139218712582176
	139218712582320 [label=PowBackward0]
	139218712582416 -> 139218712582320
	139218712582416 [label=AddBackward0]
	139218712582512 -> 139218712582416
	139218712582512 [label=SumBackward1]
	139218712582608 -> 139218712582512
	139218712582608 [label=PowBackward0]
	139218712581744 -> 139218712582608
	139218443746368 -> 139218712582176
	139218712582128 -> 139218712582080
	139218712582128 [label=DivBackward0]
	139218443746800 -> 139218712582128
	139218712582464 -> 139218712582128
	139218712582464 [label=PowBackward0]
	139218712582704 -> 139218712582464
	139218712582704 [label=AddBackward0]
	139218712582224 -> 139218712582704
	139218712582224 [label=MeanBackward1]
	139218712582800 -> 139218712582224
	139218712582800 [label=PowBackward0]
	139218712582176 -> 139218712582800
	139218443745456 -> 139218712581984
	139218443744208 -> 139218712581552
	139218443744160 -> 139218712581552
	139218443744016 -> 139218712581456
	139218443743584 -> 139218712581456
	139218712581264 -> 139218712581168
	139218712581264 [label=UpsampleBilinear2DBackward0]
	139218712581600 -> 139218712581264
	139218712581600 [label=ReluBackward0]
	139218712581840 -> 139218712581600
	139218712581840 [label=ConvolutionBackward0]
	139218712582032 -> 139218712581840
	139218712582032 [label=ReluBackward0]
	139218712582368 -> 139218712582032
	139218712582368 [label=ConvolutionBackward0]
	139218712582656 -> 139218712582368
	139218712582656 [label=CatBackward0]
	139218712582896 -> 139218712582656
	139218712582896 [label=ReluBackward0]
	139218712582944 -> 139218712582896
	139218712582944 [label=NativeGroupNormBackward0]
	139218712583040 -> 139218712582944
	139218712583040 [label=ConvolutionBackward0]
	139218712583136 -> 139218712583040
	139218712583136 [label=MulBackward0]
	139218712583232 -> 139218712583136
	139218712583232 [label=CatBackward0]
	139218443775376 -> 139218712583232
	139218712583184 -> 139218712583136
	139218712583184 [label=AddBackward0]
	139218712583280 -> 139218712583184
	139218712583280 [label=TanhBackward0]
	139218712583472 -> 139218712583280
	139218712583472 [label=AddBackward0]
	139218712583568 -> 139218712583472
	139218712583568 [label=MulBackward0]
	139218712583664 -> 139218712583568
	139218712583664 [label=MulBackward0]
	139218712583808 -> 139218712583664
	139218712583808 [label=PowBackward0]
	139218712583904 -> 139218712583808
	139218712583904 [label=AddBackward0]
	139218712584000 -> 139218712583904
	139218712584000 [label=SumBackward1]
	139218712584096 -> 139218712584000
	139218712584096 [label=PowBackward0]
	139218712583232 -> 139218712584096
	139218712478912 -> 139218712583664
	139218712583616 -> 139218712583568
	139218712583616 [label=DivBackward0]
	139218712479344 -> 139218712583616
	139218712583952 -> 139218712583616
	139218712583952 [label=PowBackward0]
	139218712584144 -> 139218712583952
	139218712584144 [label=AddBackward0]
	139218712583712 -> 139218712584144
	139218712583712 [label=MeanBackward1]
	139218712596640 -> 139218712583712
	139218712596640 [label=PowBackward0]
	139218712583664 -> 139218712596640
	139218712477952 -> 139218712583472
	139218443774944 -> 139218712583040
	139218443773504 -> 139218712583040
	139218443773072 -> 139218712582944
	139218443772640 -> 139218712582944
	139218712582752 -> 139218712582656
	139218712582752 [label=UpsampleBilinear2DBackward0]
	139218712583088 -> 139218712582752
	139218712583088 [label=ReluBackward0]
	139218712583328 -> 139218712583088
	139218712583328 [label=NativeGroupNormBackward0]
	139218712583520 -> 139218712583328
	139218712583520 [label=ConvolutionBackward0]
	139218712583856 -> 139218712583520
	139218712583856 [label=MulBackward0]
	139218712583760 -> 139218712583856
	139218712583760 [label=CatBackward0]
	139218712480976 -> 139218712583760
	139218712584048 -> 139218712583856
	139218712584048 [label=AddBackward0]
	139218712596592 -> 139218712584048
	139218712596592 [label=TanhBackward0]
	139218712596784 -> 139218712596592
	139218712596784 [label=AddBackward0]
	139218712596880 -> 139218712596784
	139218712596880 [label=MulBackward0]
	139218712596976 -> 139218712596880
	139218712596976 [label=MulBackward0]
	139218712597120 -> 139218712596976
	139218712597120 [label=PowBackward0]
	139218712597216 -> 139218712597120
	139218712597216 [label=AddBackward0]
	139218712597312 -> 139218712597216
	139218712597312 [label=SumBackward1]
	139218712597408 -> 139218712597312
	139218712597408 [label=PowBackward0]
	139218712583760 -> 139218712597408
	139218712502912 -> 139218712596976
	139218712596928 -> 139218712596880
	139218712596928 [label=DivBackward0]
	139218712503344 -> 139218712596928
	139218712597264 -> 139218712596928
	139218712597264 [label=PowBackward0]
	139218712597504 -> 139218712597264
	139218712597504 [label=AddBackward0]
	139218712597024 -> 139218712597504
	139218712597024 [label=MeanBackward1]
	139218712597600 -> 139218712597024
	139218712597600 [label=PowBackward0]
	139218712596976 -> 139218712597600
	139218712492448 -> 139218712596784
	139218712477808 -> 139218712583520
	139218712478192 -> 139218712583520
	139218443773312 -> 139218712583328
	139218712478000 -> 139218712583328
	139218443772064 -> 139218712582368
	139218443744976 -> 139218712581840
	139218443732640 -> 139218712580880
	139218443731584 -> 139218712505504
	139218443709264 -> 139218712505600
	139218443708784 -> 139218712479968
	139218443707488 -> 139218443743920
	139218443707248 -> 139218443732256
	139218443706864 -> 139218443709648
	139218443706720 -> 139218443709648
	139218443706576 -> 139218443707968
	139218443706432 -> 139218443707968
	139218443707152 -> 139218443707056
	139218615671280 [label="final.1.0.weight
 (64)" fillcolor=lightblue]
	139218615671280 -> 139218443707152
	139218443707152 [label=AccumulateGrad]
	139218443706768 -> 139218443707056
	139218615671360 [label="final.1.0.bias
 (64)" fillcolor=lightblue]
	139218615671360 -> 139218443706768
	139218443706768 [label=AccumulateGrad]
	139218615516704 -> 139218615516752
	139218615671520 [label="final.1.2.weight
 (5, 64, 3, 3)" fillcolor=lightblue]
	139218615671520 -> 139218615516704
	139218615516704 [label=AccumulateGrad]
	139218443706480 -> 139218615516752
	139218615671600 [label="final.1.2.bias
 (5)" fillcolor=lightblue]
	139218615671600 -> 139218443706480
	139218443706480 [label=AccumulateGrad]
	139218615516752 -> 139218443671968
}
